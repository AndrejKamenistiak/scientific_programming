 _______   _______  ___________  _____ _____ _____ _____ _____ 
|  ___\ \ / /  __ \|  ___| ___ \/  __ \_   _/  ___|  ___/  ___|
| |__  \ V /| /  \/| |__ | |_/ /| /  \/ | | \ `--.| |__ \ `--. 
|  __| /   \| |    |  __||    / | |     | |  `--. \  __| `--. \
| |___/ /^\ \ \__/\| |___| |\ \ | \__/\_| |_/\__/ / |___/\__/ /
\____/\/   \/\____/\____/\_| \_| \____/\___/\____/\____/\____/ 

#----------------------------------------------------------------------
# Ollama and LLMs
#----------------------------------------------------------------------

1.) Make sure the machine type of your GitHub Codespaces environment is >= 16GB.

    --> if not, you can change it before you start your GitHub Codespace 
        --> go to your Codespaces overview and click on the right side on '...'
            --> click on 'Change machine type' and select a larger machine type  

2.) Open a new VS Code Terminal and start the Ollama server (Keep the Terminal open!):

    ollama serve
    
3.) Open a second VS Code Terminal and list all available LLMs (this should be empty):

    ollama list

4.) To import an LLM like Llama3.2 (# parameters: 3B, size: 2GB), type:
    
    ollama run llama3.2:latest

5.) Test the model in the VS Code Terminal by asking questions.

6.) Quit the model:

    /bye

7.) Find running ollama processes:
   
    ps aux | grep ollama

8.) To stop all running ollama processes, type:
   
    pkill -f ollama

#----------------------------------------------------------------------
# Ollama, LLMs & Python
#----------------------------------------------------------------------

1.) Start the Ollama server again in a Terminal (Keep the Terminal open!).

    ollama serve

2.) Run the Jupyter notebook 'ollama_llms.ipynb' step by step.

3.) Try to execute the generated code.

4.) If it does not work, modify the code (e.g. using GitHub Copilot) until it works.

5.) Change the LLM and check the performance and quality of the response.

6.) Does it work well? Any issues?

#----------------------------------------------------------------------
# Text-to-SQL with OpenAI API and LangChain
#----------------------------------------------------------------------

1.) Make sure that the file ./data/credentials.json contains a valid API-key.
    Use your own or the one provided on the course day on Moodle (Week 06).
    Replace the sk--XXXX ... string in the file with the API-key.

    {
      "openai": {
        "api_key": "sk--XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX"
        }
    }

    Note that the API-key will only be available for the time of the course!

2.) Run the Jupyter notebook 'text_to_sql.ipynb' step by step.

3.) Use the SQL-agent to generate SQL-queries based on the following three questions:

    - Which is the avarage apartment price by rooms?
    - Which are the 5 cheapest apartments?
    - Which are the 5 apartments with the largest area? Show
      only the address, rooms, area and price of these apartments!

#----------------------------------------------------------------------
# Augmented analytics with OpenAI API
#----------------------------------------------------------------------

1.) Make sure that the file ./data/credentials.json contains a valid API-key.
    Use your own or the one provided on the course day on Moodle (week 06).
    Replace the sk--XXXX ... string in the file with the API-key.

    {
      "openai": {
        "api_key": "sk--XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX"
        }
    }

    Note that the API-key will only be available for the time of the course!

2.) Run the Jupyter notebook 'augmented_analytics.ipynb' step by step.

3.) Define own questions to generate Python code and data insights.

4.) Which parts work well and which not?